{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating classification dataset from the Yolo Dataset for bacils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2  \n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point this to the folder that contains your .txt label files\n",
    "labels_dir = \"\"\n",
    "\n",
    "# Paths (adjust these)\n",
    "labels_dir = Path(\"/home/julian/indonezia/dataset/instance-segmentation-dataset/dataset/08_01_dataset_negative_v1/val/labels\")  # directory with .txt label files\n",
    "images_dir = Path(\"/home/julian/indonezia/dataset/instance-segmentation-dataset/dataset/08_01_dataset_negative_v1/val/images\")  # directory with image files\n",
    "output_dir = Path(\"/home/julian/indonezia/dataset/classification_dataset_julian/val\")\n",
    "\n",
    "bacil_dir = output_dir / \"bacil\"\n",
    "debris_dir = output_dir / \"debris\"\n",
    "bacil_dir.mkdir(parents=True, exist_ok=True)\n",
    "debris_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize counters\n",
    "bacil_count = 0\n",
    "debris_count = 0\n",
    "\n",
    "polygons_by_class = {\n",
    "    0: [],  # for bacil\n",
    "    1: [],  # for debris\n",
    "}\n",
    "MAX_IMAGES_PER_CLASS = 4_000\n",
    "random.seed(42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTotal bacil (class 0) instances: 20269\\nTotal debris (class 1) instances: 26532\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify how many bacil and debris\n",
    "\n",
    "# for label_file in os.listdir(labels_dir):\n",
    "#     if not label_file.endswith(\".txt\"):\n",
    "#         continue\n",
    "    \n",
    "#     file_path = os.path.join(labels_dir, label_file)\n",
    "    \n",
    "#     with open(file_path, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             items = line.strip().split()\n",
    "#             class_id = int(items[0])\n",
    "            \n",
    "#             if class_id == 0:\n",
    "#                 bacil_count += 1\n",
    "#             elif class_id == 1:\n",
    "#                 debris_count += 1\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Total bacil (class 0) instances: {bacil_count}\")\n",
    "# print(f\"Total debris (class 1) instances: {debris_count}\")\n",
    "\n",
    "\"\"\"\n",
    "Total bacil (class 0) instances: 20269\n",
    "Total debris (class 1) instances: 26532\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNumber of images with more than 2 instance annotations: 2376\\nNumber of images with more than 1 instance annotation: 4518\\nAmong those with more than 1 instance annotation, number of images that have different classes: 0\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Check Image Instance Count multiclass and multiinstance\n",
    "\n",
    "# more_than_2_instances_count = 0\n",
    "# multi_class_images_count = 0\n",
    "\n",
    "# # We also want to track how many images have more than 1 instance (regardless of classes)\n",
    "# # This helps with the second question.\n",
    "# multi_instance_image_count = 0\n",
    "\n",
    "# # Iterate over all label files\n",
    "# for label_file in os.listdir(labels_dir):\n",
    "#     if not label_file.endswith(\".txt\"):\n",
    "#         continue\n",
    "    \n",
    "#     file_path = os.path.join(labels_dir, label_file)\n",
    "    \n",
    "#     with open(file_path, \"r\") as f:\n",
    "#         lines = f.read().strip().splitlines()\n",
    "    \n",
    "#     # Count number of instances\n",
    "#     num_instances = len(lines)\n",
    "    \n",
    "#     # Check how many images have more than 2 annotations\n",
    "#     if num_instances > 2:\n",
    "#         more_than_2_instances_count += 1\n",
    "    \n",
    "#     # For multi-class check, parse classes and see if there's more than one unique class\n",
    "#     if num_instances > 1:\n",
    "#         multi_instance_image_count += 1\n",
    "#         class_ids = []\n",
    "#         for line in lines:\n",
    "#             items = line.strip().split()\n",
    "#             class_id = items[0]  # '0' or '1' in string form\n",
    "#             class_ids.append(class_id)\n",
    "        \n",
    "#         # If there's more than one unique class, increment multi_class_images_count\n",
    "#         if len(set(class_ids)) > 1:\n",
    "#             multi_class_images_count += 1\n",
    "\n",
    "# print(f\"Number of images with more than 2 instance annotations: {more_than_2_instances_count}\")\n",
    "# print(f\"Number of images with more than 1 instance annotation: {multi_instance_image_count}\")\n",
    "# print(f\"Among those with more than 1 instance annotation, \"\n",
    "#       f\"number of images that have different classes: {multi_class_images_count}\")\n",
    "\"\"\"\n",
    "Number of images with more than 2 instance annotations: 2376\n",
    "Number of images with more than 1 instance annotation: 4518\n",
    "Among those with more than 1 instance annotation, number of images that have different classes: 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset by saving the images based on class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_by_class = {\n",
    "    0: [],  # bacil\n",
    "    1: [],  # debris\n",
    "}\n",
    "\n",
    "for label_file in labels_dir.iterdir():\n",
    "    if label_file.suffix.lower() != \".txt\":\n",
    "        continue\n",
    "\n",
    "    # Construct the matching image filename: e.g. \"image000.txt\" -> \"image000.jpg\"\n",
    "    # Adjust if your images use .png or another extension\n",
    "    image_file = images_dir / (label_file.stem + \".png\")\n",
    "    if not image_file.exists():\n",
    "        # If the image doesn't exist, skip\n",
    "        continue\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "    \n",
    "    if not lines:\n",
    "        # If no lines (no annotations), skip or treat as special case\n",
    "        continue\n",
    "\n",
    "    # Check the classes in this image\n",
    "    classes_in_image = set()\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        cls_id = int(parts[0])  # 0 or 1\n",
    "        classes_in_image.add(cls_id)\n",
    "\n",
    "    # According to your data analysis, classes_in_image should have exactly one element\n",
    "    if len(classes_in_image) == 1:\n",
    "        main_class = list(classes_in_image)[0]  # 0 or 1\n",
    "        # Only track classes 0 or 1 (in case you have other classes or noise)\n",
    "        if main_class in [0, 1]:\n",
    "            images_by_class[main_class].append(image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (bacil): found 1304 total, taking 1304\n",
      "Class 1 (debris): found 7981 total, taking 4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_images = {\n",
    "    0: [],\n",
    "    1: [],\n",
    "}\n",
    "\n",
    "for cls_id in [0, 1]:\n",
    "    img_list = images_by_class[cls_id]\n",
    "    random.shuffle(img_list)\n",
    "    selected_images[cls_id] = img_list[:MAX_IMAGES_PER_CLASS]\n",
    "\n",
    "print(f\"Class 0 (bacil): found {len(images_by_class[0])} total, taking {len(selected_images[0])}\")\n",
    "print(f\"Class 1 (debris): found {len(images_by_class[1])} total, taking {len(selected_images[1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Classification dataset created at: /home/julian/indonezia/dataset/classification_dataset_julian/val\n",
      "Bacil folder: 1304 images\n",
      "Debris folder: 4000 images\n"
     ]
    }
   ],
   "source": [
    "for cls_id in [0, 1]:\n",
    "    if cls_id == 0:\n",
    "        target_dir = bacil_dir\n",
    "    else:\n",
    "        target_dir = debris_dir\n",
    "    \n",
    "    for img_path in selected_images[cls_id]:\n",
    "        # Copy with the original filename\n",
    "        shutil.copy2(img_path, target_dir / img_path.name)\n",
    "\n",
    "print(\"Done! Classification dataset created at:\", output_dir)\n",
    "print(\"Bacil folder:\", len(list(bacil_dir.iterdir())), \"images\")\n",
    "print(\"Debris folder:\", len(list(debris_dir.iterdir())), \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset by cropping the objects and saving the cropped objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gather polygons from labels\n",
    "for label_file in labels_dir.iterdir():\n",
    "    if label_file.suffix != \".txt\":\n",
    "        continue\n",
    "    \n",
    "    # Derive image filename from label filename\n",
    "    # e.g., label_file = \"image0.txt\" -> image_file = \"image0.jpg\" (or .png)\n",
    "    # Adjust if your images have different extensions\n",
    "    image_file = images_dir / (label_file.stem + \".png\")\n",
    "    \n",
    "    # If the corresponding image does not exist, skip\n",
    "    if not image_file.exists():\n",
    "        continue\n",
    "    \n",
    "    # Read label lines\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            # Split line into tokens\n",
    "            items = line.strip().split()\n",
    "            class_id = int(items[0])\n",
    "            \n",
    "            # We only have 2 classes (0 or 1)\n",
    "            if class_id not in [0, 1]:\n",
    "                continue\n",
    "            \n",
    "            # The rest of items are polygon coordinates: x1, y1, x2, y2, ...\n",
    "            coords = items[1:]\n",
    "            \n",
    "            # Convert them to float\n",
    "            coords = [float(c) for c in coords]\n",
    "            \n",
    "            # Store it as (image_path, class_id, coords)\n",
    "            polygons_by_class[class_id].append((image_file, coords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. For each class, we only want 10,000\n",
    "MAX_PER_CLASS = 10000\n",
    "selected_polygons = {0: [], 1: []}\n",
    "\n",
    "for cls_id in [0, 1]:\n",
    "    # Shuffle the entire list to randomize\n",
    "    random.shuffle(polygons_by_class[cls_id])\n",
    "    \n",
    "    # Take up to 10,000\n",
    "    selected_polygons[cls_id] = polygons_by_class[cls_id][:MAX_PER_CLASS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Function to compute bounding box from polygon coords\n",
    "def polygon_to_bbox(coords, img_w, img_h):\n",
    "    \"\"\"\n",
    "    coords: [x1, y1, x2, y2, ..., xN, yN] in normalized format (0 to 1).\n",
    "    Returns (xmin, ymin, xmax, ymax) in absolute pixel coordinates.\n",
    "    \"\"\"\n",
    "    # coords come in pairs\n",
    "    xs = coords[0::2]  # x1, x2, ...\n",
    "    ys = coords[1::2]  # y1, y2, ...\n",
    "    \n",
    "    # Convert normalized -> absolute pixel coordinates\n",
    "    xs_abs = [int(x * img_w) for x in xs]\n",
    "    ys_abs = [int(y * img_h) for y in ys]\n",
    "    \n",
    "    xmin, xmax = min(xs_abs), max(xs_abs)\n",
    "    ymin, ymax = min(ys_abs), max(ys_abs)\n",
    "    \n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# 4. Crop and save\n",
    "def crop_and_save_polygon(image_path, coords, out_dir, index):\n",
    "    \"\"\"\n",
    "    Reads the image, crops the bounding box of the polygon,\n",
    "    and saves it to out_dir with a filename that includes `index`.\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        return  # skip if image not found or can't be opened\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    xmin, ymin, xmax, ymax = polygon_to_bbox(coords, w, h)\n",
    "    \n",
    "    # Clip coordinates in case bounding box goes out of image\n",
    "    xmin = max(0, xmin)\n",
    "    ymin = max(0, ymin)\n",
    "    xmax = min(w, xmax)\n",
    "    ymax = min(h, ymax)\n",
    "    \n",
    "    # Crop\n",
    "    cropped = img[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    # If bounding box is invalid or empty, skip\n",
    "    if cropped.size == 0:\n",
    "        return\n",
    "    \n",
    "    # Save the cropped patch\n",
    "    out_path = out_dir / f\"{image_path.stem}_{index}.png\"\n",
    "    cv2.imwrite(str(out_path), cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 0 -> /home/julian/indonezia/dataset/classification_dataset_julian/train/bacil\n",
      "Processing class 1 -> /home/julian/indonezia/dataset/classification_dataset_julian/train/debris\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (img_file, coords) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(polygons):\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mcrop_and_save_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone! Crops saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir)\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36mcrop_and_save_polygon\u001b[0;34m(image_path, coords, out_dir, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Save the cropped patch\u001b[39;00m\n\u001b[1;32m     48\u001b[0m out_path \u001b[38;5;241m=\u001b[39m out_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process each class\n",
    "for cls_id, polygons in selected_polygons.items():\n",
    "    if cls_id == 0:\n",
    "        class_dir = bacil_dir\n",
    "    else:\n",
    "        class_dir = debris_dir\n",
    "    \n",
    "    print(f\"Processing class {cls_id} -> {class_dir}\")\n",
    "    \n",
    "    for idx, (img_file, coords) in enumerate(polygons):\n",
    "        crop_and_save_polygon(img_file, coords, class_dir, idx)\n",
    "\n",
    "print(\"Done! Crops saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
